import os
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import requests

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# OpenAI Chat ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=api_key)

# URLì—ì„œ í…ìŠ¤íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ê³  í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
def fetch_blog_content(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    main_content = soup.find("section", class_="css-18vt64m")

    content = ""
    if main_content:
        # Find all h2 tags and relevant paragraphs
        award_sections = main_content.find_all("h2")
        
        for h2 in award_sections:
            text = h2.get_text(strip=True)
            # Check if this h2 is an award title (using emoji or specific keywords like ëŒ€ìƒ, ìš°ìˆ˜ìƒ)
            if any(award in text for award in ["ğŸ† ëŒ€ìƒ", "ğŸ–ï¸ ìš°ìˆ˜ìƒ", "ğŸ… ì…ì„ "]):
                # Append the award title
                content += f"\n\n### {text}\n"
                
                # Get the project name in the following <h2> tag (e.g., [Lexi Note] ì–¸ì–´ê³µë¶€ í•„ê¸° ì›¹ ì„œë¹„ìŠ¤)
                next_h2 = h2.find_next_sibling("h2")
                if next_h2:
                    project_title = next_h2.get_text(strip=True)
                    content += f"**Project Title:** {project_title}\n"
                
                # Get creator information
                creator_tag = h2.find_next("p")
                if creator_tag and creator_tag.find("strong"):
                    creators = creator_tag.find("strong").get_text(strip=True)
                    content += f"**Creators:** {creators}\n"
                
                # Find and add the description
                description_block = h2.find_next("div", class_="my-callout")
                if description_block:
                    description = description_block.get_text(strip=True)
                    content += f"**Description:** {description}\n"
                
                # Get the tech stack
                tech_stack = []
                for p in h2.find_all_next("p"):
                    if "ì‚¬ìš©í•œ ê¸°ìˆ  ìŠ¤íƒ" in p.get_text():
                        tech_stack.append(p.get_text(strip=True))
                if tech_stack:
                    content += f"**Tech Stack:** {', '.join(tech_stack)}\n"
    else:
        content = "Error: The main content could not be found. Please check the HTML structure."
    
    return content

# ë¸”ë¡œê·¸ URLì—ì„œ ë‚´ìš© ì¶”ì¶œ ë° ë¶„í• 
url = "https://spartacodingclub.kr/blog/all-in-challenge_winner"
content = fetch_blog_content(url)
documents = [Document(page_content=content)]

# ì„ë² ë”© ì €ì¥
embeddings = OpenAIEmbeddings(openai_api_key=api_key)
vector_store = Chroma.from_documents(documents, embeddings, persist_directory="chroma_store")
vector_store.persist()

# Streamlit ì„¤ì • ë° ì±—ë´‡ UI
st.title("All-in Coding Challenge RAG Chatbot")

# ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì €ì¥ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ìš©ì„ í‘œì‹œí•˜ê¸°
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(message["content"])
    else:
        with st.chat_message("assistant"):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” ì¸í„°í˜ì´ìŠ¤
if prompt := st.chat_input("ì±—ë´‡ì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ê¸°ë¡ì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
    docs = vector_store.similarity_search(prompt, k=3)  # ê°€ì¥ ê´€ë ¨ëœ ìƒìœ„ 3ê°œì˜ ë¬¸ì„œë§Œ ìš”ì•½ ìƒì„±ì— ì‚¬ìš©
    summarized_content = "\n".join([doc.page_content for doc in docs])
    
    question_template = PromptTemplate(
        input_variables=["context", "question"],
        template="ë‹¤ìŒ ë‚´ìš©ì˜ í•µì‹¬ì„ ìš”ì•½í•´ ë‹µë³€í•´ì¤˜: {context} ì§ˆë¬¸: {question}"
    )
    formatted_prompt = question_template.format(context=summarized_content, question=prompt)
    
    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
    answer = llm([HumanMessage(content=formatted_prompt)])
    with st.chat_message("assistant"):
        st.markdown(answer.content)
    st.session_state.messages.append({"role": "assistant", "content": answer.content})

    # ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ë¡œ ì €ì¥
    with open("conversation_log.txt", "a") as f:
        f.write(f"ì‚¬ìš©ì: {prompt}\nì±—ë´‡: {answer.content}\n\n")
